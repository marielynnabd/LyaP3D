""" This module provides a set of functions to get the cross power spectrum 

    P_cross(z, delta_theta, k_parallel) from quasar's Lyman-alpha forests """
 

import numpy as np
import sys, os
import glob
from astropy.table import Table, vstack
from multiprocessing import Pool

sys.path.insert(0, os.environ['HOME']+'/Software/picca/py')
from picca import constants
from picca.constants import SPEED_LIGHT # in km/s

lambda_lya = 1215.67 # Angstrom

# Computing cosmo used for Conversions
Omega_m=0.3153
Omega_k=0.
h = 0.7
Cosmo = constants.Cosmo(Omega_m, Omega_k, H0=100*h)
rcomov = Cosmo.get_r_comov
distang = Cosmo.get_dist_m
hubble = Cosmo.get_hubble
    
# Conversion from degree to Mpc
z = 2.59999
# z = 2.5
deg_to_Mpc = distang(z) * np.pi / 180


def get_possible_pairs(i_los, all_los_table, los_number, ang_sep_max, radec_names=['ra', 'dec']):
    """ - This function gets possible pairs:  
            - Takes a mock generated by mock_generation.py 
            - Returns a table of possible pairs with a max angular separation
    
    Arguments:
    ----------
    i_los: Integer
    Index of LOS with which we want to pair other LOS
    
    all_los_table: Table
    Mock
    
    los_number: Integer
    Number of LOS included in the mock
    
    ang_sep_max: Float, units = degree or Mpc/h
    Maximum angular separation possible between two LOS so that they form a pair
    
    radec_names: List of str, Default: ['ra', 'dec']
    ra dec keys in mocks or data table
    Options: - ['ra', 'dec']: my mocks
             - ['RA', 'DEC']: eBOSS data
             - ['TARGET_RA', 'TARGET_DEC']: IRON
             - ['x', 'y']
    
    Return:
    -------
    los_pairs_table: Table
    Each row corresponds to the indices of the pixels forming the pair, and the angular separation between them
    """

    ra = radec_names[0]
    dec = radec_names[1]
    
    # Initializing los_pairs_table
    los_pairs_table = Table()
    
    if radec_names == ['x', 'y']:
        cos_los = 1
    else:
        cos_los = np.cos(all_los_table[dec][i_los] * np.pi / 180)

    dalpha = all_los_table[ra][i_los+1:los_number] - all_los_table[ra][i_los]
    ddelta = all_los_table[dec][i_los+1:los_number] - all_los_table[dec][i_los]
    i_neighbors = np.arange(i_los+1, los_number)

    # Selecting a radius of 1 degree around the pixel (First selection)
    radius_degree = 1
    if radec_names == ['x', 'y']:
        radius_Mpc = radius_degree * deg_to_Mpc * h
        mask1 = (dalpha < radius_Mpc) & (ddelta < radius_Mpc) 
    else:
        mask1 = (dalpha < radius_degree) & (ddelta < radius_degree) 

    ang_sep_local = (dalpha[mask1] * cos_los)**2 + ddelta[mask1]**2
    ang_sep_local = np.sqrt(ang_sep_local)
    
    i_neighbors = i_neighbors[mask1]
    
    # Selecting pairs with angular separation < max angular separation we want (Second selection)
    mask2 = (ang_sep_local <= ang_sep_max)
    i_neighbors = i_neighbors[mask2]
    ang_sep_local = ang_sep_local[mask2]
    
    # Filling table
    los_pairs_table['index_los1'] = np.ones(len(i_neighbors), dtype='int') * i_los
    los_pairs_table['index_los2'] = i_neighbors
    los_pairs_table['ang_separation'] = ang_sep_local
    
    return los_pairs_table

def compute_resolution_correction(resolution, k_parallel, delta_v):
    """ This function computes the resolution correction for one LOS
    
    Arguments:
    ----------
    resolution: Float
    Mean resolution of LOS.
    
    k_parallel: Array
    Array of parallel wavenumber.
    
    delta_v: Float
    c x (ln_lambda_1 - ln_lambda_2).
    
    Return:
    -------
    resolution_correction: Float
    
    """
    
    resolution_correction = np.exp(-1/2 * (k_parallel * resolution)**2) * np.sinc(k_parallel * delta_v / 2 / np.pi)
    
    return resolution_correction


def compute_mean_p_cross(all_los_table, los_pairs_table, ang_sep_bin_edges, 
                         minimum_snr_p_cross=None, resolution_correction=True, 
                         data_type='mocks', units='Angstrom'):
    """ This function computes mean power spectrum for pairs with angular separations > 0 (called cross power spectrum):
          - Takes mock and corresponfing los_pairs_table
          _ Computes cross power spectrum for each pair
          - Averages over all of them to get one p_cross(k_parallel) per angular separation bin
    
    Arguments:
    ----------
    all_los_table: Table
    Mock
    
    los_pairs_table: Table
    Each row corresponds to the indices of the pixels forming the pair, and the angular separation between them
    
    ang_sep_bin_edges: Array of floats
    Edges of the angular separation bins we want to use
    
    minimum_snr_p_cross: Float, Default is None
    The value of minimum snr used for snr cut.
    
    resolution_correction: Boolean, Default is True
    If we want to apply a resolution correction or not.
    
    data_type: String, Options: 'mocks', 'real'
    The type of data set on which we want to run the cross power spectrum computation.
        - In the case of mocks: The cross power spectrum will be computed in [Angstrom] by default,
        because when we draw LOS to create mocks, wavelength = (1 + refshift) * lambda_lya [Angstrom].
        If another unit is desired, this must be specified in the argument units.
        - In the case of real data: The cross power spectrum will be first computed unitless,
        because wavelength = LOGLAM, therefore it is mandatory to multiply it my a factor c, and the output will be in [km/s].
    
    units: String, Options: 'Mpc/h', 'Angstrom', 'km/s', Default is Angstrom
    Units in which to compute power spectrum. This argument must be specified if data_type is 'mocks'.
    
    Return:
    -------
    p_cross_table: Table
    Each row corresponds to the p_cross in one angular separation bin
    """
    
    lambda_lya = 1215.67 # Angstrom
    z = 2.59999
    
    # Computing cosmo used for conversions
    Omega_m = 0.3153
    Omega_k = 0.
    h = 0.7
    Cosmo = constants.Cosmo(Omega_m, Omega_k, H0=100*h)
    rcomov = Cosmo.get_r_comov
    distang = Cosmo.get_dist_m
    hubble = Cosmo.get_hubble
    
    # Centers of angular separation bins
    ang_sep_bin_centers = np.around((ang_sep_bin_edges[1:] + ang_sep_bin_edges[:-1]) / 2, 5)
    
    print('Pcross computation')
    # Parameters definitions
    delta_lambda = all_los_table['wavelength'][0][1] - all_los_table['wavelength'][0][0]
    delta_los = all_los_table['delta_los']
    Npix = len(delta_los[0])
    print('Npix', Npix)
    
    if minimum_snr_p_cross is not None:
        print('snr cut applied')
        snr_los1 = all_los_table['MEANSNR'][ los_pairs_table['index_los1'] ]
        snr_los2 = all_los_table['MEANSNR'][ los_pairs_table['index_los2'] ]
        snr_cut = (snr_los1 > minimum_snr_p_cross) & (snr_los2 > minimum_snr_p_cross)
        
    # FFT of deltas
    fft_delta = np.fft.rfft(delta_los)
    Nk = fft_delta.shape[1] # bcz of rfft, otherwise Nk = Npix if we do fft
    
    # Initializing p_cross_table
    p_cross_table = Table()
    p_cross_table['ang_sep_bin_centers'] = np.array(ang_sep_bin_centers)
    p_cross_table['mean_ang_separation'] = np.zeros(len(ang_sep_bin_centers))
    p_cross_table['N'] = np.zeros(len(ang_sep_bin_centers))
    p_cross_table['k_parallel'] = np.zeros((len(ang_sep_bin_centers), Nk))
    p_cross_table['mean_power_spectrum'] = np.zeros((len(ang_sep_bin_centers), Nk))
    p_cross_table['error_power_spectrum'] = np.zeros((len(ang_sep_bin_centers), Nk))
    p_cross_table['resolution_correction'] = np.zeros((len(ang_sep_bin_centers), Nk))
    
    # p_cross computation
    for i_ang_sep, ang_sep in enumerate(ang_sep_bin_edges[:-1]):
        print('angular separation bin edges', ang_sep_bin_edges[i_ang_sep], ang_sep_bin_edges[i_ang_sep+1], 
              'corresponging center', ang_sep_bin_centers[i_ang_sep])
        
        select = (los_pairs_table['ang_separation'] > ang_sep_bin_edges[i_ang_sep]) & (
                los_pairs_table['ang_separation'] <= ang_sep_bin_edges[i_ang_sep+1])
        
        if minimum_snr_p_cross is not None:
            select = (select & snr_cut)

        N_pairs = np.sum(select)
        mean_ang_separation = np.mean(los_pairs_table['ang_separation'][select])
        p_cross_table['N'][i_ang_sep] = N_pairs
        p_cross_table['mean_ang_separation'][i_ang_sep] = mean_ang_separation

        index_los1 = los_pairs_table['index_los1'][select]
        index_los2 = los_pairs_table['index_los2'][select]

        # Computation of p_cross in Ansgtrom units
        p_cross = (fft_delta[index_los1] * np.conj(fft_delta[index_los2])) * delta_lambda / Npix # same units as delta_lambda
        k_parallel = 2 * np.pi * np.fft.rfftfreq(Npix, delta_lambda) # same units as delta_lambda

        # Add pixelization factor correction
        pixelization_factor = np.sinc(k_parallel * delta_lambda / (2 * np.pi))**2

        p_cross /= pixelization_factor
        
        if data_type == 'mocks':
            # If the output unit desired is not Angstrom
            if units == 'km/s':            
                conversion_factor = (1 + z) * lambda_lya / SPEED_LIGHT # from Angstrom^-1 to [km/s]^-1
                p_cross /= conversion_factor # km/s
                k_parallel *= conversion_factor # k_parallel in [km/s]^-1

            elif units == 'Mpc/h':
                conversion_factor = (hubble(z) * lambda_lya) / SPEED_LIGHT 
                p_cross /= conversion_factor # Mpc
                k_parallel *= conversion_factor # Mpc^-1
                p_cross *= h # [Mpc/h]
                k_parallel /= h # [Mpc/h]^-1
        else:
            p_cross *= SPEED_LIGHT
            k_parallel /= SPEED_LIGHT
            
        if resolution_correction == True:
            delta_v = SPEED_LIGHT * delta_lambda
            resolution_los1 = all_los_table['MEANRESOLUTION'][index_los1]
            resolution_los2 = all_los_table['MEANRESOLUTION'][index_los2]
            resolution_correction_los1 = compute_resolution_correction(resolution_los1, k_parallel, delta_v)
            resolution_correction_los2 = compute_resolution_correction(resolution_los2, k_parallel, delta_v)
            resolution_correction_p_cross = resolution_correction_los1 * resolution_correction_los2

        # mean_p_cross computation
        mean_p_cross = np.zeros(Nk)
        mean_resolution_correction_p_cross = np.zeros(Nk)
        error_p_cross = np.zeros(Nk)
        for i in range(Nk):
            mean_p_cross[i] = np.mean(p_cross.real[:,i])
            error_p_cross[i] = np.std(p_cross.real[:,i]) / np.sqrt(N_pairs - 1)
            mean_resolution_correction_p_cross[i] = np.mean(resolution_correction_p_cross[:,i])

        p_cross_table['k_parallel'][i_ang_sep, :] = k_parallel
        p_cross_table['mean_power_spectrum'][i_ang_sep, :] = mean_p_cross  
        p_cross_table['error_power_spectrum'][i_ang_sep, :] = error_p_cross
        p_cross_table['resolution_correction'][i_ang_sep, :] = mean_resolution_correction_p_cross
        
    return p_cross_table


def compute_mean_p_auto(all_los_table, minimum_snr_p_auto=None, resolution_correction=True, 
                        data_type='mocks', units='Angstrom'):
    """ This function computes mean power spectrum for angular separation = 0 (Lya forest and itself, called auto power spectrum):
          - Takes all_los_table
          - Computes auto power spectrum for each LOS 
          - Averages over all of them to get one p_auto(k_parallel) at ang_sep_bin = 0
    
    Arguments:
    ----------
    all_los_table: Table
    Mock.
    
    minimum_snr_p_auto: Float, Default is None
    The value of minimum snr used for snr cut.
    
    resolution_correction: Boolean, Default is True
    If we want to apply a resolution correction or not.
    
    data_type: String, Options: 'mocks', 'real'
    The type of data set on which we want to run the auto power spectrum computation.
        - In the case of mocks: The auto power spectrum will be computed in [Angstrom] by default,
        because when we draw LOS to create mocks, wavelength = (1 + refshift) * lambda_lya [Angstrom].
        If another unit is desired, this must be specified in the argument units.
        - In the case of real data: The auto power spectrum will be first computed unitless,
        because wavelength = LOGLAM, therefore it is mandatory to multiply it my a factor c, and the output will be in [km/s].
    
    units: String, Options: 'Mpc/h', 'Angstrom', 'km/s', Default is Angstrom
    Units in which to compute power spectrum. This argument must be specified if data_type is 'mocks'.
    
    Return:
    -------
    p_auto_table: Table
    One row table corresponding to average p_auto computed in ang_sep_bin = 0
    """
    
    z = 2.59999
    
    # Computing cosmo used for conversions
    Omega_m = 0.3153
    Omega_k = 0.
    h = 0.7
    Cosmo = constants.Cosmo(Omega_m, Omega_k, H0=100*h)
    rcomov = Cosmo.get_r_comov
    distang = Cosmo.get_dist_m
    hubble = Cosmo.get_hubble

    print('P_auto computation')
    # Parameters definitions
    delta_lambda = all_los_table['wavelength'][0][1] - all_los_table['wavelength'][0][0]
    delta_los = all_los_table['delta_los']
    Npix = len(delta_los[0])
    print('Npix', Npix)
    if minimum_snr_p_auto is not None:
        print('snr cut applied')
        snr_cut = (all_los_table['MEANSNR'] > minimum_snr_p_auto)
        delta_los = delta_los[snr_cut]
    
    # FFT of deltas
    fft_delta = np.fft.rfft(delta_los)
    Nk = fft_delta.shape[1]
    print('Nk', Nk)

    # Initializing p_auto_table
    p_auto_table = Table()
    p_auto_table['ang_sep_bin_centers'] = np.zeros((1))
    p_auto_table['mean_ang_separation'] = np.zeros((1))
    p_auto_table['N'] = np.zeros((1))
    p_auto_table['k_parallel'] = np.zeros((1, Nk))
    p_auto_table['mean_power_spectrum'] = np.zeros((1, Nk))
    p_auto_table['error_power_spectrum'] = np.zeros((1, Nk))
    p_auto_table['resolution_correction'] = np.zeros((1, Nk))
    
    # p_auto computation in Angstrom units
    p_auto = (fft_delta.real**2 + fft_delta.imag**2) * delta_lambda / Npix # same units as delta_lambda
    k_parallel = 2 * np.pi * np.fft.rfftfreq(Npix, delta_lambda) # same units as delta_lambda

    # Add pixelization factor correction
    pixelization_factor = np.sinc(k_parallel * delta_lambda / (2 * np.pi))**2

    p_auto /= pixelization_factor

    if data_type == 'mocks':
    
        if units == 'km/s':
                conversion_factor = (1 + z) * lambda_lya / SPEED_LIGHT # from Angstrom^-1 to [km/s]^-1
                p_auto /= conversion_factor # km/s
                k_parallel *= conversion_factor # k_parallel in [km/s]^-1

        elif units == 'Mpc/h':
                conversion_factor = (hubble(z) * lambda_lya) / SPEED_LIGHT # from Angstrom^-1 to Mpc^-1
                p_auto /= conversion_factor # Mpc
                k_parallel *= conversion_factor # Mpc^-1
                p_auto *= h # [Mpc/h]
                k_parallel /= h # [Mpc/h]^-1
    else:
        p_auto *= SPEED_LIGHT
        k_parallel /= SPEED_LIGHT
    
    # resolution correction computation
    if resolution_correction == True:
        delta_v = SPEED_LIGHT * delta_lambda
        resolution_los = all_los_table['MEANRESOLUTION']
        if minimum_snr_p_auto is not None:
            resolution_los = resolution_los[snr_cut]

        resolution_correction_los = compute_resolution_correction(resolution_los, k_parallel, delta_v)
        resolution_correction_p_auto = resolution_correction_los**2
       
    # mean_p_auto computation
    mean_p_auto = np.zeros(Nk)
    error_p_auto = np.zeros(Nk)
    mean_resolution_correction_p_auto = np.zeros(Nk)
    for i in range(Nk):
        mean_p_auto[i] = np.mean(p_auto[:, i])
        error_p_auto[i] = np.std(p_auto[:, i]) / np.sqrt(len(p_auto) - 1)  # TODO check len(p_auto) = n_los
        mean_resolution_correction_p_auto = np.mean(resolution_correction_p_auto[:, i])

    p_auto_table['k_parallel'][0, :] = k_parallel
    p_auto_table['mean_power_spectrum'][0, :] = mean_p_auto  
    p_auto_table['error_power_spectrum'][0, :] = error_p_auto
    p_auto_table['resolution_correction'][0, :] = mean_resolution_correction_p_auto
    p_auto_table['N'][0] = len(p_auto)
    
    return p_auto_table


def compute_mean_power_spectrum(all_los_table, los_pairs_table, ang_sep_bin_edges, data_type='mocks', 
                                units='Angstrom', minimum_snr_p_cross=None, minimum_snr_p_auto=None, 
                                resolution_correction=True):
    """ - This function computes mean_power_spectrum: 
            - Takes all_los_table and pairs (1 mock)
            - Computes mean_p_auto and mean_p_cross using above functions
            - Stacks them both in one table called mock_mean_power_spectrum

    Arguments:
    ----------
    Arguments are as defined above
    
    Return:
    -------
    mean_power_spectrum_table: Table
    Each row corresponds to the computed power spectrum in an angular spearation bin
    """

    p_cross_table = compute_mean_p_cross(all_los_table=all_los_table, los_pairs_table=los_pairs_table, 
                                         ang_sep_bin_edges=ang_sep_bin_edges,
                                         minimum_snr_p_cross=minimum_snr_p_cross, 
                                         resolution_correction=resolution_correction,
                                         data_type=data_type, units=units)
    p_auto_table = compute_mean_p_auto(all_los_table=all_los_table, 
                                       minimum_snr_p_auto=minimum_snr_p_auto, 
                                       resolution_correction=resolution_correction,
                                       data_type=data_type, units=units)
    mock_mean_power_spectrum = vstack([p_auto_table, p_cross_table])
    
    return mock_mean_power_spectrum


def wavenumber_rebin(power_spectrum_table, n_kbins):
    """ This function rebins the power spectrum into wavenumber bins
    
    Arguments:
    ----------
    power_spectrum_table: Table
    Table of mean power spectrum computed from one or several mocks
    
    n_kbins: Integer
    Number of wavenumber bins
    
    Return:
    -------
    power_spcetrum_table: Table
    Same table as in input, but with rebinned power spectrum columns added to the table
    """
    
    k_bin_edges = np.logspace(-2, np.log10(np.max(power_spectrum_table['k_parallel'][0])), num=n_kbins) # same units as k_parallel
    k_bin_centers = np.around((k_bin_edges[1:] + k_bin_edges[:-1]) / 2, 5) # same units as k_parallel
    
    power_spectrum_table['k_parallel_rebinned'] = np.zeros((len(power_spectrum_table), len(k_bin_centers))) # same units as k_parallel
    power_spectrum_table['mean_power_spectrum_rebinned'] = np.zeros((len(power_spectrum_table), len(k_bin_centers)))
    power_spectrum_table['error_power_spectrum_rebinned'] = np.zeros((len(power_spectrum_table), len(k_bin_centers)))
    
    for j in range(len(power_spectrum_table)):
    
        power_spectrum_table['k_parallel_rebinned'][j,:] = k_bin_centers

        for ik_bin, k_bin in enumerate(k_bin_edges[:-1]):

            select_k = (power_spectrum_table['k_parallel'][j] > k_bin_edges[ik_bin]) & (
                power_spectrum_table['k_parallel'][j] <= k_bin_edges[ik_bin+1])

            mean_power_spectrum_rebinned = np.mean(power_spectrum_table['mean_power_spectrum'][j][select_k])
            error_power_spectrum_rebinned = np.mean(power_spectrum_table['error_power_spectrum'][j][select_k]) / np.sqrt(np.sum(select_k))
            
            power_spectrum_table['mean_power_spectrum_rebinned'][j,ik_bin] = mean_power_spectrum_rebinned 
            power_spectrum_table['error_power_spectrum_rebinned'][j,ik_bin] = error_power_spectrum_rebinned
            
    return power_spectrum_table


def run_compute_mean_power_spectrum(mocks_dir, ncpu, ang_sep_max, n_kbins, 
                                    minimum_snr_p_cross=None, minimum_snr_p_auto=None, 
                                    k_binning=False, data_type='mocks', units='Angstrom', 
                                    radec_names=['ra', 'dec']): 
    """ - This function computes all_mocks_mean_power_spectrum:
            - Takes all mocks or one mock
            - Gets pairs table for each mock separately
            - Computes mean_p_auto and mean_p_cross for each mock separately
            - Averages over all mocks (mean of mean)
            - Does wavenumber rebinning if k_binning==True

    Arguments:
    ----------
    mocks_dir: String
    Directory where mocks fits files are located
    
    ncpu: Integer
    
    ang_sep_max: Same definition as in function get_possible_pairs
    
    n_kbins: Integer
    Number of wavenumber bins if k_binning
    
    minimum_snr_p_cross, minimum_snr_p_auto: Floats, Defaults are None
    The values of minimum snr required for both p_cross and p_auto computation.
    
    k_binning: Boolean, Default to False
    Rebin power spectrum using wavenumber_rebin function
    
    data_type: String, Options: 'mocks', 'real'
    The type of data set on which we want to run the power spectrum computation.
        - In the case of mocks: The power spectrum will be computed in [Angstrom] by default,
        because when we draw LOS to create mocks, wavelength = (1 + refshift) * lambda_lya [Angstrom].
        If another unit is desired, this must be specified in the argument units.
        - In the case of real data: The power spectrum will be first computed unitless,
        because wavelength = LOGLAM, therefore it is mandatory to multiply it my a factor c, and the output will be in [km/s].
    
    units: String, Options: 'Mpc/h', 'Angstrom', 'km/s', Default is Angstrom
    Units in which to compute power spectrum. This argument must be specified if data_type is 'mocks'.
    
    radec_names: List of str, Default: ['ra', 'dec']
    ra dec keys in mocks or data table
    Options: - ['ra', 'dec']: my mocks
             - ['RA', 'DEC']: eBOSS data
             - ['TARGET_RA', 'TARGET_DEC']: IRON
             - ['x', 'y']: Mpc/h analysis

    Return:
    -------
    final_power_spectrum: Table
    Each row corresponds to the computed mean power spectrum over all mocks in one angular spearation bin
    """
    
    z = 2.59999
    
    # Computing cosmo used for Conversions
    Omega_m = 0.3153
    Omega_k = 0.
    h = 0.7
    Cosmo = constants.Cosmo(Omega_m, Omega_k, H0=100*h)
    rcomov = Cosmo.get_r_comov
    distang = Cosmo.get_dist_m
    hubble = Cosmo.get_hubble
    
    # Conversion from degree to Mpc
    deg_to_Mpc = distang(z) * np.pi / 180

    # Loading mocks files
    searchstr = '*'
    files = glob.glob(os.path.join(mocks_dir, f"{searchstr}.fits.gz"))
    
    # Initializing all mocks mean power spectrum table
    all_mocks_mean_power_spectrum = Table()
    
    for i_f, f in enumerate(files):
    
        # Reading mock (file)
        print('Reading file test'+str(i_f+1)+'.fits.gz')
        all_los_table = Table.read(f)

        # Defining parameters used for next step
        los_number = len(all_los_table)

        # Getting los_pairs_table from mock 
        if radec_names == ['x', 'y']:
            print('Getting pairs with angular separation < '+str(ang_sep_max)+' Mpc/h')
        else:
            print('Getting pairs with angular separation < '+str(ang_sep_max)+' degrees')

        with Pool(ncpu) as pool:
            output_get_possible_pairs = pool.starmap(
                get_possible_pairs, [[i, all_los_table, los_number, ang_sep_max, radec_names] for i in range(los_number)])
        output_get_possible_pairs = [x for x in output_get_possible_pairs if x is not None] # For sanity check
        los_pairs_table = vstack([output_get_possible_pairs[i] for i in range(len(output_get_possible_pairs))])

        # Defining edges of angular separation bins used for next step
        ang_sep_bin_edges = np.array([0, 0.005, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1])
        if radec_names == ['x', 'y']:
            ang_sep_bin_edges *= deg_to_Mpc * h

        # Computing the mean_p_cross for each mock
        # print('Computing mean power spectrum in ', units)
        print('Computing mean power spectrum in input units')
        mock_mean_power_spectrum = compute_mean_power_spectrum(all_los_table=all_los_table, 
                                                               los_pairs_table=los_pairs_table, 
                                                               ang_sep_bin_edges=ang_sep_bin_edges, 
                                                               data_type=data_type, units=units,
                                                               minimum_snr_p_cross=minimum_snr_p_cross, 
                                                               minimum_snr_p_auto=minimum_snr_p_auto)
        
        # Stacking power spectra of all mocks in one table
        all_mocks_mean_power_spectrum = vstack([all_mocks_mean_power_spectrum, mock_mean_power_spectrum])  
        
    # Mean over all mocks
    N_mocks = len(files)
    if N_mocks == 1:
        print('Averaging on '+str(N_mocks)+' mock')
    else:
        print('Averaging on '+str(N_mocks)+' mocks')

    N_ang_sep_bins = int(len(all_mocks_mean_power_spectrum) / N_mocks)
    k_parallel = all_mocks_mean_power_spectrum['k_parallel'][0] 
    N_k_bins = len(k_parallel)
    ang_sep_bin_centers = np.array(all_mocks_mean_power_spectrum['ang_sep_bin_centers'][:N_ang_sep_bins])
    
    ### Initializing table
    final_power_spectrum = Table()
    final_power_spectrum['ang_sep_bin_centers'] = ang_sep_bin_centers
    final_power_spectrum['mean_ang_separation'] = np.zeros(len(ang_sep_bin_centers))
    final_power_spectrum['N'] = np.zeros(len(ang_sep_bin_centers))
    final_power_spectrum['k_parallel'] = np.zeros((len(ang_sep_bin_centers), N_k_bins))
    final_power_spectrum['mean_power_spectrum'] = np.zeros((len(ang_sep_bin_centers), N_k_bins))
    final_power_spectrum['error_power_spectrum'] = np.zeros((len(ang_sep_bin_centers), N_k_bins))
    
    ### Averaging
    for i_ang_sep, ang_sep in enumerate(ang_sep_bin_centers): 
    
        select = (all_mocks_mean_power_spectrum['ang_sep_bin_centers'] == ang_sep)

        N = np.sum(all_mocks_mean_power_spectrum['N'][select])
        final_power_spectrum['N'][i_ang_sep] = N

        mean_ang_separation = np.mean(all_mocks_mean_power_spectrum['mean_ang_separation'][select])
        final_power_spectrum['mean_ang_separation'][i_ang_sep] = mean_ang_separation

        mean = np.zeros(N_k_bins)
        error = np.zeros(N_k_bins)

        for i in range(N_k_bins):
            if N_mocks>1:
                mean[i] = np.mean(all_mocks_mean_power_spectrum['mean_power_spectrum'][select][:, i])
                error[i] = np.mean(all_mocks_mean_power_spectrum['error_power_spectrum'][select][:,i]) / np.sqrt(N_mocks - 1)
            else:
                mean[i] = all_mocks_mean_power_spectrum['mean_power_spectrum'][select][:, i]
                error[i] = all_mocks_mean_power_spectrum['error_power_spectrum'][select][:,i]

        final_power_spectrum['k_parallel'][i_ang_sep, :] = k_parallel
        final_power_spectrum['mean_power_spectrum'][i_ang_sep, :] = mean 
        final_power_spectrum['error_power_spectrum'][i_ang_sep, :] = error
        
    if k_binning:
        print('Wavenumber rebinning')
        final_power_spectrum = wavenumber_rebin(power_spectrum_table=final_power_spectrum, n_kbins=n_kbins)
        
    return final_power_spectrum

